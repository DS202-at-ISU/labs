---
title: "DS 202 - lab #4: Scraping (into) the Hall of Fame"
author: Will Ju
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: center, bottom, inverse
background-image: url(images/hof.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

<!--<img src="" class="cover" height=1500>-->

# Lab #4: Scraping (into) the Hall of Fame
---

# Big Picture Goal

We are going to contribute an extension of the Hall of Fame data in the Lahman data package for the year 2023.

# Step-by-Step

In this activity we are going to

1. identify suitable websites with data on Baseball's Hall of Fame
2. write web scrapers with the goal to 
    
    a. automate the download process, 
    b. and - as much as possible - clean the data automatically, or at least identify potential problems, to, finally, 
    c. use the scrapers in future years
    
3. use the scraper to get data for the year 2023.
4. document the process. 

The deliverables are (1) individual reports (Rmd) and (2) the dataset.

---

# Getting Ready

1. Identify your team! Go to Canvas and find out which team you are in for Lab 4.

2. If you are participating remotely, find your teammates via Slack / email. You can use any platform for collaboration that works for you all (Microsoft Teams, discord, WebEx, Zoom, etc)
If you are in the classroom, find the other members of your team and sit with them.

3. Introduce yourself to each other. 

4. Go to https://ds202-at-isu.github.io/labs/lab04.html and follow the instructions.

---

# Step-by Step

1. Accept the link to Github Classroom shared in the announcement/chat. 
  
  - This link will ask you to log in to github. Select your name from the list by clicking on it. 
  
  - Check if your team number already exists - if it does, join the team with the right number. If it doesn't exist yet, create it yourself.

2. Start a new RStudio project on your local machine using the link to the github repository.

3. Create a new RMarkdown file called `progress-report-<your github handle>.Rmd` (Mine would be called `progress-report-willju-wangqian.Rmd`). Delete everything from line 12 on. 

4. Save the file and add it to your github repository. 

5. Use this RMarkdown file for your lab notes - try to keep track of what you are doing, so you have an easier time afterward to see what worked and what didn't.

4. Commit the file and push. We are ready to roll!


---

# Data Background

The Lahman data package is based on [Sean Lahman](https://www.seanlahman.com/)'s  Baseball  [Database](https://www.seanlahman.com/baseball-archive/statistics/). 

The `HallOfFame` table is a part of this set of tables and has data up to 2022.

## Baseball Reference 

The site baseball-reference.com has grown out of Sean Lahman's work and is now maintained independently. 

Incidentally, it also has tables with Hall of Fame information, e.g. for 2023: 

https://www.baseball-reference.com/awards/hof_2023.shtml

---
# Scrape the data

Use the `rvest` package to download and parse data tables for Hall of Fame voting records. 

# Clean the data

What steps are necessary to get the scraped data into the shape as the `HallOfFame` data table:

```{r}
library(Lahman)
head(HallOfFame, 3)
```
---

# Deliverable: data

As a team, create the Hall of fame data for the year 2023.

Save the result by appending the new data frame(s) to the existing data `HallOfFame` in `Lahman` package.

```{r fig.width= 12, fig.height = 4, warning = FALSE}
HallOfFame %>% 
  ggplot(aes(x = yearID, fill = inducted)) +
  geom_bar() +
  xlim(c(1936, 2022))
```

---

# Some Data Tidying tricks

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(rvest)
url <- "https://www.baseball-reference.com/awards/hof_2023.shtml"
html <- read_html(url)
tables <- html_table(html)
```

Should you be in the situation, that a data set does not have any names, but the names are stored as the first line of records:

```{r}
head(tables[[1]], 3)
```
---

# Variable Names in Line 2

Write the dataset into a temporary file, and read the data back in (using the command `read_csv`) and skipping the first line:

```{r, message=FALSE, eval=FALSE}
write.csv(tables[[1]], "temp.csv", row.names=FALSE)
backin <- readr::read_csv("temp.csv", skip = 1, show_col_types =FALSE)
head(backin, 3)
```
---

# Functions you might need

**`parse_number`** from the `readr` package

```{r, message=FALSE}
readr::parse_number(c("34%", "10th", "1.0"))
```

**`gsub`** from R base: 

Usage `gsub(pattern, replacement, x)`:  replace all occurrences of `pattern` in vector `x` by the string `replacement`. 

```{r}
x <- c("David Ortiz", "X-Barry Bonds", "X-Roger Clemens")

gsub("X-", "Oh no! ", x)

gsub("X-", "", x)
```
---

# Combining Data sets

If two data frames have the same variable names, we can use the command **`rbind`** (row bind) to concatenate them. 

```{r}
x1 <- data.frame(id=1:2, name=c("A", "B"))
x2 <- data.frame(id=3:4, name=c("C", "D"))

rbind(x1, x2)
dframe <- rbind(x1, x2)
```

Don't forget to save the result!

---

# Exporting csv files

**`write.csv`** writes a data frame into a comma-separated values file (extension csv):

```{r, eval=FALSE}
write.csv(dframe, file="some-file.csv", row.names = FALSE)
```

Make sure to not export the row names, otherwise each successive read & write of the file adds another column in the front.



**`write_csv`** is not part of base, but faster, and does not convert special characters into `.`


```{r, eval=FALSE}
readr::write_csv(dframe, file="some-other-file.csv")
```

---

# Submission

1. Push changes to your file `progress-report-<github handle>.Rmd` to the github repo. 

2. Save the expanded `HallOfFame` as a csv file `HallOfFame.csv`. Push `HallOfFame.csv` to the team's repository.



Due date: You have time until Monday, Nov 27 at 11:59 pm to submit the final RMmarkdown file.

One team member: upload the team's repo link to Canvas (just to signal to the instructor that you are done)
